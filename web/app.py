"""
SceneWeave Web UI - Gradio ç•Œé¢
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import gradio as gr
import numpy as np

from src.core import (
    SubjectDetector,
    CompositionScorer,
    Reframer,
    AIOutpainter,
    TraditionalOutpainter,
    OutpaintDirection
)
from src.core.reframer import PaddingStrategy


# å…¨å±€å®ä¾‹
detector = None
reframer = Reframer()
scorer = CompositionScorer()
ai_outpainter = None
traditional_outpainter = TraditionalOutpainter()


def get_ai_outpainter():
    """å»¶è¿ŸåŠ è½½ AI æ‰©å›¾å™¨"""
    global ai_outpainter
    if ai_outpainter is None:
        ai_outpainter = AIOutpainter(device="cpu")
    return ai_outpainter


def get_detector():
    """å»¶è¿ŸåŠ è½½æ£€æµ‹å™¨"""
    global detector
    if detector is None:
        detector = SubjectDetector(model_size="n")
    return detector


def analyze_image(image):
    """åˆ†æå›¾ç‰‡æ„å›¾"""
    if image is None:
        return None, "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_path = "/tmp/sceneweave_input.jpg"
    import cv2
    cv2.imwrite(temp_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))

    # æ£€æµ‹ä¸»ä½“
    det = get_detector()
    subjects = det.detect(temp_path)

    # åˆ†ææ„å›¾
    main_subject = subjects[0] if subjects else None

    if main_subject:
        score = scorer.score(
            temp_path,
            subject_bbox=main_subject.bbox,
            subject_center=main_subject.center
        )
    else:
        score = scorer.score(temp_path)

    # ç”Ÿæˆåˆ†ææ–‡æœ¬
    analysis = f"""
## æ„å›¾åˆ†ææŠ¥å‘Š

### æ£€æµ‹ç»“æœ
- æ£€æµ‹åˆ° **{len(subjects)}** ä¸ªä¸»ä½“
- ä¸»è¦ä¸»ä½“: **{main_subject.label if main_subject else 'æœªæ£€æµ‹åˆ°'}**
- ä¸»ä½“ä½ç½®: ({main_subject.center[0]:.0f}, {main_subject.center[1]:.0f})" if main_subject else ""

### æ„å›¾è¯„åˆ†

| ç»´åº¦ | å¾—åˆ† | æ»¡åˆ† |
|------|------|------|
| ä¸‰åˆ†æ³•åˆ™ | {score.rule_of_thirds:.1f} | 30 |
| è§†è§‰å¹³è¡¡ | {score.visual_balance:.1f} | 25 |
| ä¸»ä½“çªå‡º | {score.subject_prominence:.1f} | 25 |
| å‘¼å¸ç©ºé—´ | {score.breathing_room:.1f} | 20 |
| **æ€»åˆ†** | **{score.total:.1f}** | **100** |

### è¯„çº§: {score.grade}

### æ”¹è¿›å»ºè®®
"""
    issues = scorer.get_issues()
    if issues:
        for issue in issues:
            analysis += f"\n- **{issue.description}**\n  - {issue.suggestion}"
    else:
        analysis += "\n\nâœ… æ„å›¾è‰¯å¥½, æ— éœ€æ”¹è¿›!"

    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
    result_img = det.draw_detections(temp_path, subjects)

    return result_img, analysis


def reframe_image(image, ratio, padding):
    """é‡æ„å›¾"""
    if image is None:
        return None, None, None, None

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_path = "/tmp/sceneweave_input.jpg"
    import cv2
    cv2.imwrite(temp_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))

    # è§£ææ¯”ä¾‹
    ratio_map = {
        "1:1 æ­£æ–¹å½¢ (Instagram)": (1, 1),
        "4:5 ç«–å›¾ (Instagram/å°çº¢ä¹¦)": (4, 5),
        "16:9 æ¨ªå± (YouTube)": (16, 9),
        "9:16 ç«–å± (Story/æŠ–éŸ³)": (9, 16),
        "2:3 å°é¢ (å°çº¢ä¹¦)": (2, 3),
        "3:1 Banner": (3, 1),
    }
    target_ratio = ratio_map[ratio]

    # è§£æå¡«å……ç­–ç•¥
    padding_map = {
        "ä¸å¡«å…… (è£å‰ª)": PaddingStrategy.NONE,
        "æ¨¡ç³ŠèƒŒæ™¯": PaddingStrategy.BLUR,
        "çº¯è‰²å¡«å…… (ç™½è‰²)": PaddingStrategy.COLOR,
        "é•œåƒå¡«å……": PaddingStrategy.MIRROR,
    }
    padding_strategy = padding_map[padding]

    # æ£€æµ‹ä¸»ä½“
    det = get_detector()
    subjects = det.detect(temp_path)
    main_subject = subjects[0] if subjects else None

    # é‡æ„å›¾
    result = reframer.reframe(
        temp_path,
        target_ratio=target_ratio,
        subject_center=main_subject.center if main_subject else None,
        subject_bbox=main_subject.bbox if main_subject else None,
        padding=padding_strategy
    )

    # ç”Ÿæˆæ‰€æœ‰é¢„è®¾ç‰ˆæœ¬
    all_results = []
    for r_name, r_val in ratio_map.items():
        r = reframer.reframe(
            temp_path,
            target_ratio=r_val,
            subject_center=main_subject.center if main_subject else None,
            subject_bbox=main_subject.bbox if main_subject else None,
            padding=padding_strategy
        )
        all_results.append((r_name, r.image))

    # åˆ›å»ºå¯¹æ¯”å›¾
    h = max(image.shape[0], result.image.shape[0])
    orig_resized = cv2.resize(image, (int(image.shape[1] * h / image.shape[0]), h))
    result_resized = cv2.resize(result.image, (int(result.image.shape[1] * h / result.image.shape[0]), h))

    # æ·»åŠ æ ‡ç­¾
    def add_label(img, label):
        labeled = np.zeros((img.shape[0] + 40, img.shape[1], 3), dtype=np.uint8)
        labeled[40:, :] = img
        cv2.putText(labeled, label, (10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        return labeled

    orig_labeled = add_label(orig_resized, "Original")
    result_labeled = add_label(result_resized, "Reframed")
    comparison = np.hstack([orig_labeled, result_labeled])

    return result.image, comparison, all_results, f"å°ºå¯¸: {result.original_size} -> {result.new_size}"


def outpaint_image(image, direction, expand_pixels, prompt, use_ai):
    """AI æ‰©å›¾"""
    if image is None:
        return None, "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_path = "/tmp/sceneweave_input.jpg"
    import cv2
    cv2.imwrite(temp_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))

    # è§£ææ–¹å‘
    direction_map = {
        "å‘å·¦æ‰©å±•": OutpaintDirection.LEFT,
        "å‘å³æ‰©å±•": OutpaintDirection.RIGHT,
        "å‘ä¸Šæ‰©å±•": OutpaintDirection.TOP,
        "å‘ä¸‹æ‰©å±•": OutpaintDirection.BOTTOM,
        "å››å‘¨æ‰©å±•": OutpaintDirection.ALL,
    }
    direction_enum = direction_map[direction]

    try:
        if use_ai:
            # ä½¿ç”¨ AI æ‰©å›¾
            outpainter = get_ai_outpainter()
            result = outpainter.outpaint(
                temp_path,
                direction=direction_enum,
                expand_pixels=expand_pixels,
                prompt=prompt or "high quality, detailed, natural extension",
                num_inference_steps=30,  # å‡å°‘æ­¥æ•°åŠ å¿«é€Ÿåº¦
                guidance_scale=7.5
            )
            info = f"AI æ‰©å›¾å®Œæˆ | è€—æ—¶: {result.generation_time:.2f}s | å°ºå¯¸: {result.original_size} -> {result.new_size}"
        else:
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
            outpainter = traditional_outpainter
            result_image = outpainter.extend(image, direction_enum, expand_pixels)

            from src.core.outpainter import OutpaintResult
            result = OutpaintResult(
                image=result_image,
                original_size=(image.shape[1], image.shape[0]),
                new_size=(result_image.shape[1], result_image.shape[0]),
                direction=direction_enum,
                expand_pixels=expand_pixels,
                mask=None,
                generation_time=0
            )
            info = f"ä¼ ç»Ÿæ‰©å›¾å®Œæˆ | å°ºå¯¸: {result.original_size} -> {result.new_size}"

        return result.image, info

    except Exception as e:
        return None, f"æ‰©å›¾å¤±è´¥: {str(e)}"


# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(
    title="SceneWeave - AI æ™ºèƒ½é‡æ„å›¾",
    theme=gr.themes.Soft()
) as app:

    gr.Markdown("""
    # SceneWeave - AI æ™ºèƒ½å›¾ç‰‡é‡æ„å›¾å·¥å…·
    è®©æ¯ä¸€å¼ ç…§ç‰‡éƒ½æˆä¸ºå®Œç¾æ„å›¾ | æ”¯æŒ AI æ™ºèƒ½æ‰©å›¾
    """)

    with gr.Tabs():
        # Tab 1: æ„å›¾åˆ†æ
        with gr.Tab("æ„å›¾åˆ†æ"):
            with gr.Row():
                with gr.Column():
                    input_image = gr.Image(label="ä¸Šä¼ å›¾ç‰‡")
                    analyze_btn = gr.Button("åˆ†ææ„å›¾", variant="primary")

                with gr.Column():
                    detection_result = gr.Image(label="æ£€æµ‹ç»“æœ")
                    analysis_result = gr.Markdown(label="åˆ†ææŠ¥å‘Š")

            analyze_btn.click(
                analyze_image,
                inputs=[input_image],
                outputs=[detection_result, analysis_result]
            )

        # Tab 2: æ™ºèƒ½é‡æ„å›¾
        with gr.Tab("æ™ºèƒ½é‡æ„å›¾"):
            with gr.Row():
                with gr.Column():
                    reframe_input = gr.Image(label="ä¸Šä¼ å›¾ç‰‡")
                    ratio_select = gr.Dropdown(
                        choices=[
                            "1:1 æ­£æ–¹å½¢ (Instagram)",
                            "4:5 ç«–å›¾ (Instagram/å°çº¢ä¹¦)",
                            "16:9 æ¨ªå± (YouTube)",
                            "9:16 ç«–å± (Story/æŠ–éŸ³)",
                            "2:3 å°é¢ (å°çº¢ä¹¦)",
                            "3:1 Banner",
                        ],
                        value="4:5 ç«–å›¾ (Instagram/å°çº¢ä¹¦)",
                        label="ç›®æ ‡æ¯”ä¾‹"
                    )
                    padding_select = gr.Dropdown(
                        choices=[
                            "ä¸å¡«å…… (è£å‰ª)",
                            "æ¨¡ç³ŠèƒŒæ™¯",
                            "çº¯è‰²å¡«å…… (ç™½è‰²)",
                            "é•œåƒå¡«å……",
                        ],
                        value="æ¨¡ç³ŠèƒŒæ™¯",
                        label="å¡«å……ç­–ç•¥"
                    )
                    reframe_btn = gr.Button("å¼€å§‹é‡æ„å›¾", variant="primary")

                with gr.Column():
                    reframe_output = gr.Image(label="é‡æ„å›¾ç»“æœ")
                    comparison_output = gr.Image(label="å¯¹æ¯”è§†å›¾")
                    size_info = gr.Text(label="å°ºå¯¸ä¿¡æ¯")

            reframe_btn.click(
                reframe_image,
                inputs=[reframe_input, ratio_select, padding_select],
                outputs=[reframe_output, comparison_output, gr.State(), size_info]
            )

        # Tab 3: æ‰¹é‡ç”Ÿæˆ
        with gr.Tab("æ‰¹é‡ç”Ÿæˆ"):
            gr.Markdown("### ä¸€é”®ç”Ÿæˆæ‰€æœ‰å¸¸ç”¨æ¯”ä¾‹")

            with gr.Row():
                batch_input = gr.Image(label="ä¸Šä¼ å›¾ç‰‡")
                batch_padding = gr.Dropdown(
                    choices=[
                        "ä¸å¡«å…… (è£å‰ª)",
                        "æ¨¡ç³ŠèƒŒæ™¯",
                        "çº¯è‰²å¡«å…… (ç™½è‰²)",
                        "é•œåƒå¡«å……",
                    ],
                    value="æ¨¡ç³ŠèƒŒæ™¯",
                    label="å¡«å……ç­–ç•¥"
                )
                batch_btn = gr.Button("ç”Ÿæˆæ‰€æœ‰ç‰ˆæœ¬", variant="primary")

            with gr.Row():
                batch_gallery = gr.Gallery(label="æ‰€æœ‰ç‰ˆæœ¬", columns=3)

            batch_btn.click(
                reframe_image,
                inputs=[batch_input, gr.State("4:5 ç«–å›¾ (Instagram/å°çº¢ä¹¦)"), batch_padding],
                outputs=[gr.State(), gr.State(), batch_gallery, gr.State()]
            )

        # Tab 4: AI æ‰©å›¾
        with gr.Tab("AI æ‰©å›¾"):
            gr.Markdown("""
            ### ğŸ¤– AI æ™ºèƒ½æ‰©å›¾
            ä½¿ç”¨ Stable Diffusion è¿›è¡Œæ™ºèƒ½å›¾ç‰‡æ‰©å±•
            """)

            with gr.Row():
                with gr.Column():
                    outpaint_input = gr.Image(label="ä¸Šä¼ å›¾ç‰‡")
                    direction_select = gr.Dropdown(
                        choices=[
                            "å‘å·¦æ‰©å±•",
                            "å‘å³æ‰©å±•",
                            "å‘ä¸Šæ‰©å±•",
                            "å‘ä¸‹æ‰©å±•",
                            "å››å‘¨æ‰©å±•",
                        ],
                        value="å››å‘¨æ‰©å±•",
                        label="æ‰©å±•æ–¹å‘"
                    )
                    expand_pixels = gr.Slider(
                        minimum=64,
                        maximum=512,
                        value=256,
                        step=64,
                        label="æ‰©å±•åƒç´ æ•°"
                    )
                    prompt_input = gr.Textbox(
                        label="æç¤ºè¯ (å¯é€‰)",
                        placeholder="æè¿°ä½ æƒ³è¦æ‰©å±•çš„å†…å®¹ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆ"
                    )
                    use_ai = gr.Checkbox(
                        label="ä½¿ç”¨ AI æ‰©å›¾ (å–æ¶ˆåˆ™ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•)",
                        value=True
                    )
                    outpaint_btn = gr.Button("å¼€å§‹æ‰©å›¾", variant="primary")

                with gr.Column():
                    outpaint_output = gr.Image(label="æ‰©å›¾ç»“æœ")
                    outpaint_info = gr.Text(label="å¤„ç†ä¿¡æ¯")

            outpaint_btn.click(
                outpaint_image,
                inputs=[outpaint_input, direction_select, expand_pixels, prompt_input, use_ai],
                outputs=[outpaint_output, outpaint_info]
            )

    gr.Markdown("""
    ---
    **ä½¿ç”¨è¯´æ˜:**
    1. ä¸Šä¼ å›¾ç‰‡
    2. é€‰æ‹©ç›®æ ‡æ¯”ä¾‹å’Œå¡«å……ç­–ç•¥
    3. ç‚¹å‡»æŒ‰é’®ç”Ÿæˆé‡æ„å›¾

    **æç¤º:** æ¨¡ç³ŠèƒŒæ™¯å¡«å……æ•ˆæœæœ€å¥½, é€‚åˆç¤¾äº¤åª’ä½“å‘å¸ƒ
    """)


if __name__ == "__main__":
    app.launch(server_name="0.0.0.0", server_port=7860)
